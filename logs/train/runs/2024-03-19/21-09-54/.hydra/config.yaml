datamodule:
  data_dir: /workspaces/research_project_template/data
  val_split: 0.1
  num_workers: 20
  normalize: true
  batch_size: 128
  seed: 42
  shuffle: true
  pin_memory: true
  drop_last: false
  _target_: project.datamodules.mnist.MNISTDataModule
  train_transforms:
    _target_: project.configs.datamodule.mnist_train_transforms
  val_transforms: null
  test_transforms: null
algorithm:
  lr_scheduler:
    T_max: 85
    eta_min: 1.0e-05
    last_epoch: -1
    verbose: false
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
  lr_scheduler_interval: epoch
  lr_scheduler_frequency: 1
  max_epochs: 90
  optimizer:
    lr: 0.0003
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.0
    amsgrad: false
    _target_: torch.optim.adam.Adam
    _partial_: true
  batch_size: 128
  early_stopping_patience: 0
network:
  pretrained: false
  num_classes: ${instance_attr:datamodule.num_classes,datamodule.action_dims}
  _target_: torchvision.models.resnet.resnet18
trainer:
  _target_: lightning.Trainer
  logger: null
  accelerator: gpu
  strategy: auto
  devices: 1
  min_epochs: 1
  max_epochs: 90
  default_root_dir: ${hydra:runtime.output_dir}
  detect_anomaly: false
  callbacks:
    model_checkpoint:
      _target_: lightning.pytorch.callbacks.ModelCheckpoint
      dirpath: ${hydra:runtime.output_dir}/checkpoints
      filename: epoch_{epoch:03d}
      monitor: val/loss
      verbose: false
      save_last: true
      save_top_k: 1
      mode: min
      auto_insert_metric_name: false
      save_weights_only: false
      every_n_train_steps: null
      train_time_interval: null
      every_n_epochs: null
      save_on_train_epoch_end: null
    early_stopping:
      _target_: lightning.pytorch.callbacks.EarlyStopping
      monitor: val/loss
      min_delta: 0.0
      patience: 5
      verbose: false
      mode: min
      strict: true
      check_finite: true
      stopping_threshold: null
      divergence_threshold: null
      check_on_train_epoch_end: null
    model_summary:
      _target_: lightning.pytorch.callbacks.RichModelSummary
      max_depth: 2
    rich_progress_bar:
      _target_: lightning.pytorch.callbacks.RichProgressBar
log_level: info
seed: 59259
name: train
debug: false
verbose: false
