# Config for the Jax RL Example (PPO).
# To run this, use the following command:
# ```
# python project/main.py algorithm=jax_ppo trainer=jax
# ```

_target_: project.algorithms.jax_ppo.JaxRLExample.create
env:
  _target_: gymnax.environments.classic_control.pendulum.Pendulum
env_params:
  _target_: gymnax.environments.classic_control.pendulum.EnvParams
  dt: 0.05
  g: 10.0
  l: 1.0
  m: 1.0
  max_speed: 8.0
  max_steps_in_episode: 200
  max_torque: 2.0
hp:
  _target_: project.algorithms.jax_ppo.PPOHParams
  clip_eps: 0.2
  debug: false
  ent_coef: 0.0
  eval_freq: 2000
  gae_lambda: 0.95
  gamma: 0.995
  learning_rate: 0.001
  max_grad_norm: 10
  normalize_observations: true
  num_envs: 100
  num_epochs: 10
  num_minibatches: 10
  num_steps: 100
  total_timesteps: 150000
  vf_coef: 0.5
