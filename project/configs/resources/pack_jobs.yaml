# @package _global_
defaults:
  - override /hydra/launcher: custom_submitit_slurm
trainer:
  accelerator: gpu
  devices: 1

hydra:
  mode: MULTIRUN
  verbose: True
  run:
    # NOTE: Unsure if this gets used, since we hard-set the `MULTIRUN` mode.
    dir: logs/${name}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}/task{oc.env:SLURM_PROCID}
  #   # output directory, generated dynamically on each run
  #   subdir: ${oc.env:SLURM_PROCID,}  # NOTE: Can't add this here unfortunately.
  sweep:
    dir: logs/${name}/multiruns/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: job${hydra.job.num}_task${oc.env:SLURM_PROCID}
  launcher:
    job_config:
      cpus: 4
      ram_gb: 8  # TODO: Specify the amount of RAM needed for a single run.
      gpus: ${trainer.devices}
      vram_gb: 5
      gpu_type: rtx8000
      share_cpus_between_runs: True
      parallel_runs_per_job: null

    nodes: 1
    cpus_per_task: 4
    array_parallelism: 10  # max num of jobs to run in parallel
    # Other things to pass to `sbatch`:
    additional_parameters:
      time: 1-00:00:00  # maximum wall time allocated for the job (D-HH:MM:SS)
      requeue: True
    ## A list of commands to add to the generated sbatch script before running srun:
    setup:
    - unset CUDA_VISIBLE_DEVICES

#     # NOTE: `mem_per_task` is a good way to think about this according to @obilaniu, but it
#     # unfortunately isn't a flag of `sbatch`. You can get the same result by setting `mem_per_cpu`:
#     # `mem_per_cpu = "mem_per_task" / cpus_per_task`
#     # In this example, we want "mem_per_task" of 16G:
    # mem_per_cpu: "${int_divide:16,${.cpus_per_task}}G"
