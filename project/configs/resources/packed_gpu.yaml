# @package _global_
defaults:
  - override /hydra/launcher: submitit_slurm

trainer:
  devices: 1
hydra:
  mode: MULTIRUN
  run:
    # output directory, generated dynamically on each run
    dir: logs/${name}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: logs/${name}/multiruns
    subdir: ${hydra.job.id}
  launcher:
    _target_: project.utils.packing_launcher_plugin.PackedSlurmLauncher
    submitit_folder: ${hydra.sweep.dir}/%j
    cpus_per_task: 2
    array_parallelism: 16 # max num of jobs to run in parallel
    # Other things to pass to `sbatch`:
    # gres: "gpu:1"
    # nodes: 1
    # mem_gb: 16
    stderr_to_stdout: true
    additional_parameters:
      time: 1-00:00:00 # maximum wall time allocated for the job (D-HH:MM:SS)
      mem_per_cpu: "4GB"
      ntasks_per_gpu: ???



    ## A list of commands to add to the generated sbatch script before running srun:
    # setup:
    # - export LD_PRELOAD=/some/folder/with/libraries/
