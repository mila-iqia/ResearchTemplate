batch.attention_mask:
  device: cpu
  max: 1
  mean: '8.374e-02'
  min: 0
  shape:
  - 32
  - 128
  sum: 343
batch.input_ids:
  device: cpu
  max: 26101
  mean: '1.597e+02'
  min: 0
  shape:
  - 32
  - 128
  sum: 654306
batch.labels:
  device: cpu
  max: 1
  mean: '7.188e-01'
  min: 0
  shape:
  - 32
  sum: 23
batch.token_type_ids:
  device: cpu
  max: 0
  mean: '0.e+00'
  min: 0
  shape:
  - 32
  - 128
  sum: 0
grads.network.albert.embeddings.LayerNorm.bias:
  device: cpu
  max: '9.495e-03'
  mean: '-1.080e-05'
  min: '-1.796e-02'
  shape:
  - 128
  sum: '-1.383e-03'
grads.network.albert.embeddings.LayerNorm.weight:
  device: cpu
  max: '1.186e-02'
  mean: '-2.625e-04'
  min: '-1.228e-02'
  shape:
  - 128
  sum: '-3.360e-02'
grads.network.albert.embeddings.position_embeddings.weight:
  device: cpu
  max: '6.970e-01'
  mean: '-3.638e-12'
  min: '-1.086e+00'
  shape:
  - 512
  - 128
  sum: '-2.384e-07'
grads.network.albert.embeddings.token_type_embeddings.weight:
  device: cpu
  max: '6.053e-01'
  mean: '-1.863e-09'
  min: '-1.119e+00'
  shape:
  - 2
  - 128
  sum: '-4.768e-07'
grads.network.albert.embeddings.word_embeddings.weight:
  device: cpu
  max: '1.541e+00'
  mean: '-2.008e-13'
  min: '-6.233e-01'
  shape:
  - 30000
  - 128
  sum: '-7.711e-07'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias:
  device: cpu
  max: '6.357e-02'
  mean: '-3.738e-04'
  min: '-6.593e-02'
  shape:
  - 768
  sum: '-2.871e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight:
  device: cpu
  max: '8.125e-02'
  mean: '1.121e-04'
  min: '-5.811e-01'
  shape:
  - 768
  sum: '8.612e-02'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias:
  device: cpu
  max: '6.013e-02'
  mean: '-1.940e-11'
  min: '-5.395e-02'
  shape:
  - 768
  sum: '-1.490e-08'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight:
  device: cpu
  max: '1.061e-01'
  mean: '4.042e-13'
  min: '-1.112e-01'
  shape:
  - 768
  - 768
  sum: '2.384e-07'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias:
  device: cpu
  max: '1.275e-08'
  mean: '-1.333e-11'
  min: '-6.650e-09'
  shape:
  - 768
  sum: '-1.023e-08'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight:
  device: cpu
  max: '6.536e-01'
  mean: '4.320e-06'
  min: '-3.507e-01'
  shape:
  - 768
  - 768
  sum: '2.548e+00'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias:
  device: cpu
  max: '2.402e-02'
  mean: '2.56e-05'
  min: '-1.913e-02'
  shape:
  - 768
  sum: '1.966e-02'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight:
  device: cpu
  max: '1.087e-01'
  mean: '7.314e-07'
  min: '-1.164e-01'
  shape:
  - 768
  - 768
  sum: '4.314e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias:
  device: cpu
  max: '6.786e-02'
  mean: '-3.315e-04'
  min: '-8.925e-02'
  shape:
  - 768
  sum: '-2.546e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight:
  device: cpu
  max: '4.607e-01'
  mean: '-6.091e-06'
  min: '-3.011e-01'
  shape:
  - 768
  - 768
  sum: '-3.592e+00'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias:
  device: cpu
  max: '4.213e-02'
  mean: '-3.888e-05'
  min: '-6.737e-02'
  shape:
  - 3072
  sum: '-1.195e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight:
  device: cpu
  max: '2.953e-01'
  mean: '-5.795e-07'
  min: '-2.323e-01'
  shape:
  - 3072
  - 768
  sum: '-1.367e+00'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias:
  device: cpu
  max: '5.003e-02'
  mean: '-5.821e-11'
  min: '-5.843e-02'
  shape:
  - 768
  sum: '-4.470e-08'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight:
  device: cpu
  max: '6.105e-01'
  mean: '-2.627e-12'
  min: '-5.125e-01'
  shape:
  - 768
  - 3072
  sum: '-6.199e-06'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias:
  device: cpu
  max: '6.435e-02'
  mean: '-1.912e-04'
  min: '-6.824e-02'
  shape:
  - 768
  sum: '-1.468e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight:
  device: cpu
  max: '5.071e-02'
  mean: '-6.398e-04'
  min: '-4.395e-01'
  shape:
  - 768
  sum: '-4.914e-01'
grads.network.albert.encoder.embedding_hidden_mapping_in.bias:
  device: cpu
  max: '7.07e-03'
  mean: '-8.878e-05'
  min: '-7.231e-03'
  shape:
  - 768
  sum: '-6.818e-02'
grads.network.albert.encoder.embedding_hidden_mapping_in.weight:
  device: cpu
  max: '8.686e-02'
  mean: '2.216e-06'
  min: '-8.327e-02'
  shape:
  - 768
  - 128
  sum: '2.178e-01'
grads.network.albert.pooler.bias:
  device: cpu
  max: '1.253e-02'
  mean: '5.213e-05'
  min: '-8.348e-03'
  shape:
  - 768
  sum: '4.004e-02'
grads.network.albert.pooler.weight:
  device: cpu
  max: '9.280e-02'
  mean: '-9.552e-07'
  min: '-6.335e-02'
  shape:
  - 768
  - 768
  sum: '-5.634e-01'
grads.network.classifier.bias:
  device: cpu
  max: '2.129e-01'
  mean: '7.451e-09'
  min: '-2.129e-01'
  shape:
  - 2
  sum: '1.490e-08'
grads.network.classifier.weight:
  device: cpu
  max: '2.222e-01'
  mean: '-3.444e-10'
  min: '-2.222e-01'
  shape:
  - 2
  - 768
  sum: '-5.29e-07'
outputs.labels:
  device: cpu
  max: 1
  mean: '7.188e-01'
  min: 0
  shape:
  - 32
  sum: 23
outputs.loss:
  device: cpu
  max: '7.185e-01'
  mean: '7.185e-01'
  min: '7.185e-01'
  shape: []
  sum: '7.185e-01'
outputs.preds:
  device: cpu
  max: 1
  mean: '4.688e-01'
  min: 0
  shape:
  - 32
  sum: 15
