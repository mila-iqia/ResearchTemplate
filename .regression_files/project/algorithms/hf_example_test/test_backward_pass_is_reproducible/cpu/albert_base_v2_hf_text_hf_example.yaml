batch.attention_mask:
  device: cpu
  hash: -5248677368460617222
  max: 1
  mean: 0.1
  min: 0
  shape:
  - 32
  - 128
  sum: 343
batch.input_ids:
  device: cpu
  hash: -8391087330217722819
  max: 26101
  mean: 159.7
  min: 0
  shape:
  - 32
  - 128
  sum: 654306
batch.labels:
  device: cpu
  hash: -3945588999998408889
  max: 1
  mean: 0.7
  min: 0
  shape:
  - 32
  sum: 23
batch.token_type_ids:
  device: cpu
  hash: -8123354182314851848
  max: 0
  mean: 0.0
  min: 0
  shape:
  - 32
  - 128
  sum: 0
grads.network.albert.embeddings.LayerNorm.bias:
  device: cpu
  hash: -5920310354634101490
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 128
  sum: -0.0
grads.network.albert.embeddings.LayerNorm.weight:
  device: cpu
  hash: 1495199703706422543
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 128
  sum: -0.0
grads.network.albert.embeddings.position_embeddings.weight:
  device: cpu
  hash: 8312579073978250016
  max: 0.7
  mean: -0.0
  min: -1.1
  shape:
  - 512
  - 128
  sum: -0.0
grads.network.albert.embeddings.token_type_embeddings.weight:
  device: cpu
  hash: 5648598979644007236
  max: 0.6
  mean: -0.0
  min: -1.1
  shape:
  - 2
  - 128
  sum: -0.0
grads.network.albert.embeddings.word_embeddings.weight:
  device: cpu
  hash: 2530531288551604645
  max: 1.5
  mean: 0.0
  min: -0.6
  shape:
  - 30000
  - 128
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias:
  device: cpu
  hash: -1782613338419147020
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  sum: -0.3
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight:
  device: cpu
  hash: -41391884229616695
  max: 0.1
  mean: 0.0
  min: -0.6
  shape:
  - 768
  sum: 0.1
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias:
  device: cpu
  hash: -138945345552048577
  max: 0.1
  mean: 0.0
  min: -0.1
  shape:
  - 768
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight:
  device: cpu
  hash: -4394483000722222828
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  - 768
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias:
  device: cpu
  hash: -102184048410365625
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight:
  device: cpu
  hash: -1739967336605920848
  max: 0.7
  mean: 0.0
  min: -0.4
  shape:
  - 768
  - 768
  sum: 2.5
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias:
  device: cpu
  hash: -6616697550866251608
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight:
  device: cpu
  hash: 2633268435127448452
  max: 0.1
  mean: 0.0
  min: -0.1
  shape:
  - 768
  - 768
  sum: 0.4
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias:
  device: cpu
  hash: -8183954254464469665
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  sum: -0.3
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight:
  device: cpu
  hash: -7578977790955420463
  max: 0.5
  mean: -0.0
  min: -0.3
  shape:
  - 768
  - 768
  sum: -3.6
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias:
  device: cpu
  hash: 978027301421189184
  max: 0.0
  mean: -0.0
  min: -0.1
  shape:
  - 3072
  sum: -0.1
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight:
  device: cpu
  hash: -1887359160625339601
  max: 0.3
  mean: -0.0
  min: -0.2
  shape:
  - 3072
  - 768
  sum: -1.4
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias:
  device: cpu
  hash: 3951323850735401156
  max: 0.1
  mean: 0.0
  min: -0.1
  shape:
  - 768
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight:
  device: cpu
  hash: 7713917013293806707
  max: 0.6
  mean: -0.0
  min: -0.5
  shape:
  - 768
  - 3072
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias:
  device: cpu
  hash: -4984127495978023183
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  sum: -0.1
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight:
  device: cpu
  hash: 7694067277738610739
  max: 0.1
  mean: -0.0
  min: -0.4
  shape:
  - 768
  sum: -0.5
grads.network.albert.encoder.embedding_hidden_mapping_in.bias:
  device: cpu
  hash: -2076057465744782901
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  sum: -0.1
grads.network.albert.encoder.embedding_hidden_mapping_in.weight:
  device: cpu
  hash: -6118293898610612575
  max: 0.1
  mean: 0.0
  min: -0.1
  shape:
  - 768
  - 128
  sum: 0.2
grads.network.albert.pooler.bias:
  device: cpu
  hash: -4263797609054554573
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.0
grads.network.albert.pooler.weight:
  device: cpu
  hash: 5060410091089164025
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  - 768
  sum: -0.6
grads.network.classifier.bias:
  device: cpu
  hash: -9223332094692037178
  max: 0.2
  mean: 0.0
  min: -0.2
  shape:
  - 2
  sum: 0.0
grads.network.classifier.weight:
  device: cpu
  hash: 8951598922282221134
  max: 0.2
  mean: -0.0
  min: -0.2
  shape:
  - 2
  - 768
  sum: -0.0
outputs.labels:
  device: cpu
  hash: -3945588999998408889
  max: 1
  mean: 0.7
  min: 0
  shape:
  - 32
  sum: 23
outputs.loss:
  device: cpu
  hash: 8272900287826686472
  max: 0.7
  mean: 0.7
  min: 0.7
  shape: []
  sum: 0.7
outputs.preds:
  device: cpu
  hash: -6012386395022832702
  max: 1
  mean: 0.5
  min: 0
  shape:
  - 32
  sum: 15
