batch.attention_mask:
  device: cpu
  hash: -5248677368460617222
  max: 1
  mean: 0.1
  min: 0
  shape:
  - 32
  - 128
  sum: 343
batch.input_ids:
  device: cpu
  hash: -8391087330217722819
  max: 26101
  mean: 159.7
  min: 0
  shape:
  - 32
  - 128
  sum: 654306
batch.labels:
  device: cpu
  hash: -3945588999998408889
  max: 1
  mean: 0.7
  min: 0
  shape:
  - 32
  sum: 23
batch.token_type_ids:
  device: cpu
  hash: -8123354182314851848
  max: 0
  mean: 0.0
  min: 0
  shape:
  - 32
  - 128
  sum: 0
grads.network.albert.embeddings.LayerNorm.bias:
  device: cpu
  hash: 3164521306086379693
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 128
  sum: 0.0
grads.network.albert.embeddings.LayerNorm.weight:
  device: cpu
  hash: -3047870419539418388
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 128
  sum: -0.0
grads.network.albert.embeddings.position_embeddings.weight:
  device: cpu
  hash: 7939539947078227736
  max: 0.1
  mean: 0.0
  min: -0.4
  shape:
  - 512
  - 128
  sum: 0.0
grads.network.albert.embeddings.token_type_embeddings.weight:
  device: cpu
  hash: 6751923864738017149
  max: 0.3
  mean: -0.0
  min: -1.1
  shape:
  - 2
  - 128
  sum: -0.0
grads.network.albert.embeddings.word_embeddings.weight:
  device: cpu
  hash: -1777301467538679946
  max: 0.1
  mean: -0.0
  min: -0.3
  shape:
  - 30000
  - 128
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias:
  device: cpu
  hash: -4684811361816166914
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  sum: -0.2
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight:
  device: cpu
  hash: -6061191073772350209
  max: 0.0
  mean: -0.0
  min: -0.4
  shape:
  - 768
  sum: -0.2
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias:
  device: cpu
  hash: 6318202235747969647
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight:
  device: cpu
  hash: 4145456475111198041
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  - 768
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias:
  device: cpu
  hash: -6221368371389734728
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight:
  device: cpu
  hash: 4144683943878703418
  max: 0.3
  mean: 0.0
  min: -0.2
  shape:
  - 768
  - 768
  sum: 1.4
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias:
  device: cpu
  hash: 2432157498219240006
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight:
  device: cpu
  hash: 4433245348302878655
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  - 768
  sum: 0.3
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias:
  device: cpu
  hash: 6891807040192409690
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.2
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight:
  device: cpu
  hash: 4688042221227771356
  max: 0.2
  mean: -0.0
  min: -0.2
  shape:
  - 768
  - 768
  sum: -2.3
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias:
  device: cpu
  hash: -8480442192452236723
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 3072
  sum: -0.1
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight:
  device: cpu
  hash: 9016235337638268231
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 3072
  - 768
  sum: -0.1
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias:
  device: cpu
  hash: -6006479742268296542
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  sum: -0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight:
  device: cpu
  hash: -7853704051842147315
  max: 0.3
  mean: 0.0
  min: -0.3
  shape:
  - 768
  - 3072
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias:
  device: cpu
  hash: 428697447090851765
  max: 0.1
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.0
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight:
  device: cpu
  hash: -7686688936261628980
  max: 0.0
  mean: -0.0
  min: -0.3
  shape:
  - 768
  sum: -0.3
grads.network.albert.encoder.embedding_hidden_mapping_in.bias:
  device: cpu
  hash: 8535927910160623736
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  sum: -0.0
grads.network.albert.encoder.embedding_hidden_mapping_in.weight:
  device: cpu
  hash: 157036485863524700
  max: 0.0
  mean: -0.0
  min: -0.0
  shape:
  - 768
  - 128
  sum: -0.1
grads.network.albert.pooler.bias:
  device: cpu
  hash: -346762580853883270
  max: 0.0
  mean: 0.0
  min: -0.0
  shape:
  - 768
  sum: 0.1
grads.network.albert.pooler.weight:
  device: cpu
  hash: -5827894865876388484
  max: 0.1
  mean: -0.0
  min: -0.1
  shape:
  - 768
  - 768
  sum: -1.2
grads.network.classifier.bias:
  device: cpu
  hash: -4672899744815637452
  max: 0.2
  mean: 0.0
  min: -0.2
  shape:
  - 2
  sum: 0.0
grads.network.classifier.weight:
  device: cpu
  hash: -8843256516227728937
  max: 0.2
  mean: -0.0
  min: -0.2
  shape:
  - 2
  - 768
  sum: -0.0
outputs.labels:
  device: cpu
  hash: -3945588999998408889
  max: 1
  mean: 0.7
  min: 0
  shape:
  - 32
  sum: 23
outputs.loss:
  device: cpu
  hash: 1287410195914297480
  max: 0.7
  mean: 0.7
  min: 0.7
  shape: []
  sum: 0.7
outputs.preds:
  device: cpu
  hash: -1328589377773520981
  max: 1
  mean: 0.9
  min: 0
  shape:
  - 32
  sum: 28
