batch.attention_mask:
  device: cpu
  max: 1
  mean: '8.374e-02'
  min: 0
  shape:
  - 32
  - 128
  sum: 343
batch.input_ids:
  device: cpu
  max: 26101
  mean: '1.597e+02'
  min: 0
  shape:
  - 32
  - 128
  sum: 654306
batch.labels:
  device: cpu
  max: 1
  mean: '7.188e-01'
  min: 0
  shape:
  - 32
  sum: 23
batch.token_type_ids:
  device: cpu
  max: 0
  mean: '0.e+00'
  min: 0
  shape:
  - 32
  - 128
  sum: 0
grads.network.albert.embeddings.LayerNorm.bias:
  device: cpu
  max: '9.494e-03'
  mean: '-1.081e-05'
  min: '-1.796e-02'
  shape:
  - 128
  sum: '-1.384e-03'
grads.network.albert.embeddings.LayerNorm.weight:
  device: cpu
  max: '1.186e-02'
  mean: '-2.625e-04'
  min: '-1.228e-02'
  shape:
  - 128
  sum: '-3.360e-02'
grads.network.albert.embeddings.position_embeddings.weight:
  device: cpu
  max: '6.971e-01'
  mean: '-9.095e-12'
  min: '-1.086e+00'
  shape:
  - 512
  - 128
  sum: '-5.960e-07'
grads.network.albert.embeddings.token_type_embeddings.weight:
  device: cpu
  max: '6.053e-01'
  mean: '-4.657e-09'
  min: '-1.119e+00'
  shape:
  - 2
  - 128
  sum: '-1.192e-06'
grads.network.albert.embeddings.word_embeddings.weight:
  device: cpu
  max: '1.541e+00'
  mean: '3.492e-14'
  min: '-6.232e-01'
  shape:
  - 30000
  - 128
  sum: '1.341e-07'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias:
  device: cpu
  max: '6.357e-02'
  mean: '-3.738e-04'
  min: '-6.593e-02'
  shape:
  - 768
  sum: '-2.870e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight:
  device: cpu
  max: '8.125e-02'
  mean: '1.121e-04'
  min: '-5.810e-01'
  shape:
  - 768
  sum: '8.613e-02'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias:
  device: cpu
  max: '6.013e-02'
  mean: '1.940e-11'
  min: '-5.395e-02'
  shape:
  - 768
  sum: '1.490e-08'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight:
  device: cpu
  max: '1.061e-01'
  mean: '-2.324e-12'
  min: '-1.112e-01'
  shape:
  - 768
  - 768
  sum: '-1.371e-06'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias:
  device: cpu
  max: '7.916e-09'
  mean: '-6.855e-12'
  min: '-5.835e-09'
  shape:
  - 768
  sum: '-5.265e-09'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight:
  device: cpu
  max: '6.536e-01'
  mean: '4.320e-06'
  min: '-3.507e-01'
  shape:
  - 768
  - 768
  sum: '2.548e+00'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias:
  device: cpu
  max: '2.402e-02'
  mean: '2.56e-05'
  min: '-1.913e-02'
  shape:
  - 768
  sum: '1.966e-02'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight:
  device: cpu
  max: '1.087e-01'
  mean: '7.314e-07'
  min: '-1.164e-01'
  shape:
  - 768
  - 768
  sum: '4.314e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias:
  device: cpu
  max: '6.786e-02'
  mean: '-3.315e-04'
  min: '-8.925e-02'
  shape:
  - 768
  sum: '-2.546e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight:
  device: cpu
  max: '4.607e-01'
  mean: '-6.091e-06'
  min: '-3.011e-01'
  shape:
  - 768
  - 768
  sum: '-3.593e+00'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias:
  device: cpu
  max: '4.212e-02'
  mean: '-3.888e-05'
  min: '-6.737e-02'
  shape:
  - 3072
  sum: '-1.194e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight:
  device: cpu
  max: '2.953e-01'
  mean: '-5.795e-07'
  min: '-2.323e-01'
  shape:
  - 3072
  - 768
  sum: '-1.367e+00'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias:
  device: cpu
  max: '5.003e-02'
  mean: '8.731e-11'
  min: '-5.843e-02'
  shape:
  - 768
  sum: '6.706e-08'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight:
  device: cpu
  max: '6.105e-01'
  mean: '-5.053e-12'
  min: '-5.125e-01'
  shape:
  - 768
  - 3072
  sum: '-1.192e-05'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias:
  device: cpu
  max: '6.435e-02'
  mean: '-1.912e-04'
  min: '-6.824e-02'
  shape:
  - 768
  sum: '-1.468e-01'
grads.network.albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight:
  device: cpu
  max: '5.072e-02'
  mean: '-6.398e-04'
  min: '-4.395e-01'
  shape:
  - 768
  sum: '-4.914e-01'
grads.network.albert.encoder.embedding_hidden_mapping_in.bias:
  device: cpu
  max: '7.07e-03'
  mean: '-8.878e-05'
  min: '-7.23e-03'
  shape:
  - 768
  sum: '-6.818e-02'
grads.network.albert.encoder.embedding_hidden_mapping_in.weight:
  device: cpu
  max: '8.686e-02'
  mean: '2.216e-06'
  min: '-8.327e-02'
  shape:
  - 768
  - 128
  sum: '2.178e-01'
grads.network.albert.pooler.bias:
  device: cpu
  max: '1.253e-02'
  mean: '5.213e-05'
  min: '-8.348e-03'
  shape:
  - 768
  sum: '4.004e-02'
grads.network.albert.pooler.weight:
  device: cpu
  max: '9.280e-02'
  mean: '-9.552e-07'
  min: '-6.335e-02'
  shape:
  - 768
  - 768
  sum: '-5.634e-01'
grads.network.classifier.bias:
  device: cpu
  max: '2.129e-01'
  mean: '0.e+00'
  min: '-2.129e-01'
  shape:
  - 2
  sum: '0.e+00'
grads.network.classifier.weight:
  device: cpu
  max: '2.222e-01'
  mean: '-4.657e-10'
  min: '-2.222e-01'
  shape:
  - 2
  - 768
  sum: '-7.153e-07'
outputs.labels:
  device: cpu
  max: 1
  mean: '7.188e-01'
  min: 0
  shape:
  - 32
  sum: 23
outputs.loss:
  device: cpu
  max: '7.185e-01'
  mean: '7.185e-01'
  min: '7.185e-01'
  shape: []
  sum: '7.185e-01'
outputs.preds:
  device: cpu
  max: 1
  mean: '4.688e-01'
  min: 0
  shape:
  - 32
  sum: 15
